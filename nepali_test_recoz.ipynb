{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Nepali Character Recognition system\n",
    "\n",
    "### <font color=\"blue\">Team: </font>  \n",
    "### <font color=\"blue\">1)Kashi Bhattarai</font>  \n",
    "### <font color=\"blue\">2)Birav Bhattarai</font>  \n",
    "### <font color=\"blue\">2)Jimmy Das</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimage\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "# import random\n",
    "from sklearn import ensemble,preprocessing\n",
    "import keras.utils.np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the image matrix =  62668800\n"
     ]
    }
   ],
   "source": [
    "path = \"./Sample/Train_Full_Data/\"\n",
    "\n",
    "\n",
    "folders = os.listdir(path)\n",
    "imageList=[]\n",
    "imageMatrix = []\n",
    "newIm = []\n",
    "labels=[]\n",
    "# Get list of folders in current path\n",
    "for folder in folders:\n",
    "    newPath = path + folder  #Create new path by adding folder name\n",
    "    folderName = os.path.split(os.path.abspath(newPath))[1]\n",
    "    characterName = folderName.split(\"_\")[2]\n",
    "    imageList=[f for f in os.listdir(newPath) if os.path.splitext(f)[-1] == '.png'] #Check if PNG files only then add\n",
    "    for image in imageList:   #Traverse the list of files and add each file name to the imageFile\n",
    "        im = Image.open(newPath+\"//\"+image)\n",
    "        labels.append(characterName)\n",
    "        imageArray = np.asarray(im.getdata())\n",
    "        flattenedImageArray = imageArray.flatten()\n",
    "        imageMatrix.append(flattenedImageArray)\n",
    "print(\"Size of the image matrix = \",np.size(imageMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "labe = open(\"labels.pickle\", \"wb\")\n",
    "pickle.dump(X, labe)\n",
    "labe.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = open('labels.pickle', 'rb')\n",
    "Z = pickle.load(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61200, 1024)\n"
     ]
    }
   ],
   "source": [
    "a = np.array(imageMatrix)\n",
    "a\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features size =  (61200, 1024)\n",
      "Labels size =  (61200,)\n",
      "['yna' 'yna' 'yna' ... 'jha' 'jha' 'jha']\n"
     ]
    }
   ],
   "source": [
    "#define variables\n",
    "n_samples = len(a)\n",
    "X = a.reshape((n_samples,-1))\n",
    "T = np.array(labels)\n",
    "print('Features size = ',X.shape)\n",
    "print('Labels size = ',T.shape)\n",
    "print(T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=preprocessing.LabelEncoder()\n",
    "le.fit(T)\n",
    "T=le.transform(T)\n",
    "\n",
    "T=keras.utils.np_utils.to_categorical(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adna': 0, 'ba': 1, 'bha': 2, 'cha': 3, 'chha': 4, 'chhya': 5, 'da': 6, 'daa': 7, 'dha': 8, 'dhaa': 9, 'ga': 10, 'gha': 11, 'gya': 12, 'ha': 13, 'ja': 14, 'jha': 15, 'ka': 16, 'kha': 17, 'kna': 18, 'la': 19, 'ma': 20, 'motosaw': 21, 'na': 22, 'pa': 23, 'patalosaw': 24, 'petchiryakha': 25, 'pha': 26, 'ra': 27, 'taamatar': 28, 'tabala': 29, 'tha': 30, 'thaa': 31, 'tra': 32, 'waw': 33, 'yaw': 34, 'yna': 35}\n"
     ]
    }
   ],
   "source": [
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, T_train, T_test = train_test_split(X, T, test_size=0.3, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  (42840, 1024)   (42840, 36)\n"
     ]
    }
   ],
   "source": [
    "print('Train size = ',X_train.shape,\" \",T_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import models, layers, losses, optimizers, metrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder,OneHotEncoder\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height_rows = 32\n",
    "img_width_cols = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "im_shape = (img_height_rows, img_width_cols, 1)\n",
    "print(im_shape)\n",
    "x_train = X_train.reshape(X_train.shape[0], *im_shape) # Python TIP :the * operator unpacks the tuple\n",
    "x_test = X_test.reshape(X_test.shape[0], *im_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# algorithm start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn = Sequential()\n",
    "\n",
    "kernelSize = (3, 3)\n",
    "ip_activation = 'relu'\n",
    "ip_conv_0 = Conv2D(filters=4, kernel_size=kernelSize, input_shape=im_shape, activation=ip_activation)\n",
    "cnn.add(ip_conv_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the next Convolutional+Activation layer\n",
    "ip_conv_0_1 = Conv2D(filters=4, kernel_size=kernelSize, activation=ip_activation)\n",
    "cnn.add(ip_conv_0_1)\n",
    "\n",
    "# Add the Pooling layer\n",
    "pool_0 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")\n",
    "cnn.add(pool_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_conv_1 = Conv2D(filters=4, kernel_size=kernelSize, activation=ip_activation)\n",
    "cnn.add(ip_conv_1)\n",
    "ip_conv_1_1 = Conv2D(filters=4, kernel_size=kernelSize, activation=ip_activation)\n",
    "cnn.add(ip_conv_1_1)\n",
    "\n",
    "pool_1 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")\n",
    "cnn.add(pool_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_layer_0 = Flatten()\n",
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add the Dense layers\n",
    "h_dense_0 = Dense(units=20, activation=ip_activation, kernel_initializer='uniform')\n",
    "cnn.add(h_dense_0)\n",
    "# Let's add one more before proceeding to the output layer\n",
    "h_dense_1 = Dense(units=1024, activation=ip_activation, kernel_initializer='uniform',name='dense11')\n",
    "cnn.add(h_dense_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 36\n",
    "op_activation = 'softmax'\n",
    "output_layer = Dense(units=n_classes, activation=op_activation, kernel_initializer='uniform')\n",
    "cnn.add(output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "# Compile the classifier using the configuration we want\n",
    "cnn.compile(optimizer=opt, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 30, 30, 4)         40        \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 4)         148       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 4)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 12, 12, 4)         148       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 10, 10, 4)         148       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 5, 5, 4)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                2020      \n",
      "                                                                 \n",
      " dense11 (Dense)             (None, 1024)              21504     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 36)                36900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,908\n",
      "Trainable params: 60,908\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "429/429 [==============================] - 41s 96ms/step - loss: 0.1373 - accuracy: 0.9505 - val_loss: 0.4272 - val_accuracy: 0.8988\n",
      "Epoch 2/30\n",
      "429/429 [==============================] - 76s 178ms/step - loss: 0.1325 - accuracy: 0.9528 - val_loss: 0.4000 - val_accuracy: 0.9028\n",
      "Epoch 3/30\n",
      "429/429 [==============================] - 23s 53ms/step - loss: 0.1322 - accuracy: 0.9537 - val_loss: 0.3924 - val_accuracy: 0.8998\n",
      "Epoch 4/30\n",
      "429/429 [==============================] - 23s 54ms/step - loss: 0.1275 - accuracy: 0.9550 - val_loss: 0.4560 - val_accuracy: 0.8955\n",
      "Epoch 5/30\n",
      "429/429 [==============================] - 22s 52ms/step - loss: 0.1280 - accuracy: 0.9547 - val_loss: 0.3965 - val_accuracy: 0.9042\n",
      "Epoch 6/30\n",
      "429/429 [==============================] - 22s 50ms/step - loss: 0.1168 - accuracy: 0.9595 - val_loss: 0.4324 - val_accuracy: 0.9028\n",
      "Epoch 7/30\n",
      "429/429 [==============================] - 21s 50ms/step - loss: 0.1195 - accuracy: 0.9567 - val_loss: 0.4114 - val_accuracy: 0.9066\n",
      "Epoch 8/30\n",
      "429/429 [==============================] - 21s 49ms/step - loss: 0.1129 - accuracy: 0.9605 - val_loss: 0.4512 - val_accuracy: 0.9010\n",
      "Epoch 9/30\n",
      "429/429 [==============================] - 21s 50ms/step - loss: 0.1109 - accuracy: 0.9605 - val_loss: 0.4618 - val_accuracy: 0.8955\n",
      "Epoch 10/30\n",
      "429/429 [==============================] - 21s 49ms/step - loss: 0.1106 - accuracy: 0.9614 - val_loss: 0.4491 - val_accuracy: 0.8994\n",
      "Epoch 11/30\n",
      "429/429 [==============================] - 21s 49ms/step - loss: 0.1039 - accuracy: 0.9640 - val_loss: 0.4391 - val_accuracy: 0.9031\n",
      "Epoch 12/30\n",
      "429/429 [==============================] - 22s 50ms/step - loss: 0.1095 - accuracy: 0.9614 - val_loss: 0.4466 - val_accuracy: 0.8992\n",
      "Epoch 13/30\n",
      "429/429 [==============================] - 21s 49ms/step - loss: 0.1062 - accuracy: 0.9622 - val_loss: 0.4621 - val_accuracy: 0.9011\n",
      "Epoch 14/30\n",
      "429/429 [==============================] - 21s 49ms/step - loss: 0.1015 - accuracy: 0.9634 - val_loss: 0.4502 - val_accuracy: 0.9038\n",
      "Epoch 15/30\n",
      "429/429 [==============================] - 22s 51ms/step - loss: 0.1026 - accuracy: 0.9633 - val_loss: 0.4535 - val_accuracy: 0.9042\n",
      "Epoch 16/30\n",
      "429/429 [==============================] - 24s 57ms/step - loss: 0.0911 - accuracy: 0.9675 - val_loss: 0.4420 - val_accuracy: 0.9030\n",
      "Epoch 17/30\n",
      "429/429 [==============================] - 22s 51ms/step - loss: 0.1000 - accuracy: 0.9644 - val_loss: 0.4516 - val_accuracy: 0.9026\n",
      "Epoch 18/30\n",
      "429/429 [==============================] - 23s 53ms/step - loss: 0.0930 - accuracy: 0.9677 - val_loss: 0.4504 - val_accuracy: 0.9060\n",
      "Epoch 19/30\n",
      "429/429 [==============================] - 24s 56ms/step - loss: 0.0929 - accuracy: 0.9670 - val_loss: 0.5086 - val_accuracy: 0.8959\n",
      "Epoch 20/30\n",
      "429/429 [==============================] - 22s 52ms/step - loss: 0.1035 - accuracy: 0.9634 - val_loss: 0.4565 - val_accuracy: 0.9029\n",
      "Epoch 21/30\n",
      "429/429 [==============================] - 22s 52ms/step - loss: 0.0856 - accuracy: 0.9695 - val_loss: 0.5471 - val_accuracy: 0.8956\n",
      "Epoch 22/30\n",
      "429/429 [==============================] - 22s 52ms/step - loss: 0.0850 - accuracy: 0.9700 - val_loss: 0.5024 - val_accuracy: 0.9009\n",
      "Epoch 23/30\n",
      "429/429 [==============================] - 22s 52ms/step - loss: 0.0880 - accuracy: 0.9686 - val_loss: 0.5370 - val_accuracy: 0.8944\n",
      "Epoch 24/30\n",
      "429/429 [==============================] - 22s 52ms/step - loss: 0.0895 - accuracy: 0.9683 - val_loss: 0.4902 - val_accuracy: 0.8999\n",
      "Epoch 25/30\n",
      "429/429 [==============================] - 22s 52ms/step - loss: 0.0824 - accuracy: 0.9699 - val_loss: 0.5539 - val_accuracy: 0.8969\n",
      "Epoch 26/30\n",
      "429/429 [==============================] - 23s 53ms/step - loss: 0.0838 - accuracy: 0.9700 - val_loss: 0.4668 - val_accuracy: 0.9071\n",
      "Epoch 27/30\n",
      "429/429 [==============================] - 23s 53ms/step - loss: 0.0738 - accuracy: 0.9736 - val_loss: 0.5236 - val_accuracy: 0.9048\n",
      "Epoch 28/30\n",
      "429/429 [==============================] - 22s 52ms/step - loss: 0.0858 - accuracy: 0.9702 - val_loss: 0.4991 - val_accuracy: 0.9049\n",
      "Epoch 29/30\n",
      "429/429 [==============================] - 22s 52ms/step - loss: 0.0866 - accuracy: 0.9701 - val_loss: 0.4972 - val_accuracy: 0.9017\n",
      "Epoch 30/30\n",
      "429/429 [==============================] - 24s 57ms/step - loss: 0.0768 - accuracy: 0.9725 - val_loss: 0.4833 - val_accuracy: 0.9070\n"
     ]
    }
   ],
   "source": [
    "history = cnn.fit(x_train, T_train,\n",
    "                  batch_size=100, epochs=30,\n",
    "                  validation_data=(x_test, T_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.70%\n"
     ]
    }
   ],
   "source": [
    "# model is beeing save\n",
    "scores = cnn.evaluate(x_test, T_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('final1_model.sav', 'wb') as f:\n",
    "# with open('model.pkl', 'wb') as f:\n",
    "#     pickle.dump(cnn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# model = pickle.load(open('final1_model.sav', 'rb'))\n",
    "# cnn.save('my_model1')\n",
    "cnn.save('my_model')\n",
    "\n",
    "# with open('model.pkl', 'rb') as f:\n",
    "#         model = pickle.load(f)\n",
    "        \n",
    "# self written code for reading the models\n",
    "\n",
    "# pickle_in = open(\"model.pkl\",\"rb\")\n",
    "# classifier=pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pickle_in = open(\"model.pkl\",\"rb\")\n",
    "# classifier=pickle.load(pickle_in)\n",
    "new_model = tf.keras.models.load_model('my_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 30, 30, 4)         40        \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 4)         148       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 4)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 12, 12, 4)         148       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 10, 10, 4)         148       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 5, 5, 4)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                2020      \n",
      "                                                                 \n",
      " dense11 (Dense)             (None, 1024)              21504     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 36)                36900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,908\n",
      "Trainable params: 60,908\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 32, 1),\n",
       " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[500].shape, T_train[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 1.5957469e-31, 3.2241785e-13, 1.3603431e-27,\n",
       "        5.8546791e-25, 1.0000000e+00, 2.2249144e-27, 0.0000000e+00,\n",
       "        5.3484956e-22, 0.0000000e+00, 9.7648925e-37, 3.4936094e-21,\n",
       "        2.7828892e-10, 8.1789020e-24, 2.7939705e-34, 1.7703607e-28,\n",
       "        2.5559392e-29, 2.5598288e-32, 3.1342459e-35, 1.6491910e-25,\n",
       "        5.0980779e-24, 4.0488626e-18, 3.4578074e-23, 1.3252741e-24,\n",
       "        1.6264543e-19, 0.0000000e+00, 7.2383956e-32, 3.3117355e-21,\n",
       "        4.6146360e-28, 3.0214284e-27, 6.5183024e-24, 0.0000000e+00,\n",
       "        9.0943124e-15, 2.7920551e-25, 9.2995541e-20, 7.6996732e-26]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_model.predict(x_train[0:])\n",
    "output1 = new_model.predict(x_train[500].reshape(1, 32, 32, 1))\n",
    "output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 5\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# print(output1.shape)\n",
    "# output2 = output1.reshape(36, 1)\n",
    "greatest = float('-inf')\n",
    "pos = 0\n",
    "for i in range(len(output1[0])):\n",
    "#     print(output1[0][i], end=\", \")\n",
    "    if greatest < output1[0][i]:\n",
    "        greatest = output1[0][i]\n",
    "        pos = i  \n",
    "print(greatest, pos)\n",
    "output1 = [0]*36\n",
    "output1[pos] = 1\n",
    "print(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, array(['adna', 'ba', 'bha', 'cha', 'chha', 'chhya', 'da', 'daa', 'dha',\n",
       "        'dhaa', 'ga', 'gha', 'gya', 'ha', 'ja', 'jha', 'ka', 'kha', 'kna',\n",
       "        'la', 'ma', 'motosaw', 'na', 'pa', 'patalosaw', 'petchiryakha',\n",
       "        'pha', 'ra', 'taamatar', 'tabala', 'tha', 'thaa', 'tra', 'waw',\n",
       "        'yaw', 'yna'], dtype='<U12'))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(labels)), np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(x_train[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 32, 1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = x_train[0].reshape(1, 32, 32, 1)\n",
    "input1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0]*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # path = \"/testFiles/word2_0.png\"\n",
    "# # path = \"testFiles/1414.png\"\n",
    "# path = ('./testFiles/word1_0.png')\n",
    "\n",
    "\n",
    "\n",
    "# folders = os.listdir(path)\n",
    "# imageList=[]\n",
    "# imageMatrix = []\n",
    "# newIm = []\n",
    "# # labels=[]\n",
    "# # Get list of folders in current path\n",
    "# for folder in folders:\n",
    "#     newPath = path + folder  #Create new path by adding folder name\n",
    "#     folderName = os.path.split(os.path.abspath(newPath))[1]\n",
    "#     characterName = folderName.split(\"_\")[2]\n",
    "#     imageList=[f for f in os.listdir(newPath) if os.path.splitext(f)[-1] == '.png'] #Check if PNG files only then add\n",
    "#     for image in imageList:   #Traverse the list of files and add each file name to the imageFile\n",
    "#         im = Image.open(newPath+\"//\"+image)\n",
    "#         labels.append(characterName)\n",
    "#         imageArray = np.asarray(im.getdata())\n",
    "#         flattenedImageArray = imageArray.flatten()\n",
    "#         imageMatrix.append(flattenedImageArray)\n",
    "#         break\n",
    "#     break\n",
    "        \n",
    "# print(\"Size of the image matrix = \",np.size(imageMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im = Image.open( \"testFiles/random4.png\")\n",
    "# # print(im.shape)\n",
    "# imageArray = np.asarray(im.getdata())\n",
    "# flattenedImageArray = imageArray.flatten()\n",
    "# imageMatrix.append(flattenedImageArray)\n",
    "# word1 = np.array(imageMatrix)\n",
    "# print(word1.shape)\n",
    "# word1 = word1.reshape((1, -1))\n",
    "# word1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n",
      "0.9999801 32\n",
      "tra\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('testFiles/random2.png', cv.IMREAD_GRAYSCALE )\n",
    "print(img.shape)\n",
    "img1 =img.reshape((1, 32, 32, 1))\n",
    "plt.imshow(img)\n",
    "output = new_model.predict(img1)\n",
    "\n",
    "def get_output(output1):\n",
    "    greatest = float('-inf')\n",
    "    pos = 0\n",
    "    for i in range(len(output1[0])):\n",
    "    #     print(output1[0][i], end=\", \")\n",
    "        if greatest < output1[0][i]:\n",
    "            greatest = output1[0][i]\n",
    "            pos = i  \n",
    "    print(greatest, pos)\n",
    "    output1 = [0]*36\n",
    "    output1[pos] = 1\n",
    "    print(np.unique(labels)[pos])\n",
    "    \n",
    "get_output(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[0].reshape(1, 32, 32, 1)\n",
    "\n",
    "\n",
    "# img = cv.imread('wordr1.PNG', cv.IMREAD_GRAYSCALE )\n",
    "# # print(img.shape)\n",
    "# # img1 =img.reshape((1, 32, 32, 1))\n",
    "# # plt.imshow(img)\n",
    "# # output = new_model.predict(img1)\n",
    "\n",
    "# img2 = cv.resize(img, (32, 32,0))\n",
    "# print(img2.shape)\n",
    "# plt.imshow(img2)\n",
    "\n",
    "# img3 =img2.reshape((1, 32, 32, 1))\n",
    "# img3.shape\n",
    "# # plt.imshow(img3)\n",
    "# output = new_model.predict(img3)   \n",
    "# print(output)\n",
    "# def get_output(output1):\n",
    "#     greatest = float('-inf')\n",
    "#     pos = 0\n",
    "#     for i in range(len(output1[0])):\n",
    "#     #     print(output1[0][i], end=\", \")\n",
    "#         if greatest < output1[0][i]:\n",
    "#             greatest = output1[0][i]\n",
    "#             pos = i  \n",
    "#     print(greatest, pos)\n",
    "#     output1 = [0]*36\n",
    "#     output1[pos] = 1\n",
    "#     print(np.unique(labels)[pos])\n",
    "\n",
    "# get_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['adna', 'ba', 'bha', 'cha', 'chha', 'chhya', 'da', 'daa', 'dha',\n",
       "       'dhaa', 'ga', 'gha', 'gya', 'ha', 'ja', 'jha', 'ka', 'kha', 'kna',\n",
       "       'la', 'ma', 'motosaw', 'na', 'pa', 'patalosaw', 'petchiryakha',\n",
       "       'pha', 'ra', 'taamatar', 'tabala', 'tha', 'thaa', 'tra', 'waw',\n",
       "       'yaw', 'yna'], dtype='<U12')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42840, 32, 32, 1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n",
      "0.9997271 18\n",
      "kna\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('testFiles/random3.png', cv.IMREAD_GRAYSCALE )\n",
    "print(img.shape)\n",
    "img1 =img.reshape((1, 32, 32, 1))\n",
    "plt.imshow(img)\n",
    "output = new_model.predict(img1)\n",
    "\n",
    "def get_output(output1):\n",
    "    greatest = float('-inf')\n",
    "    pos = 0\n",
    "    for i in range(len(output1[0])):\n",
    "    #     print(output1[0][i], end=\", \")\n",
    "        if greatest < output1[0][i]:\n",
    "            greatest = output1[0][i]\n",
    "            pos = i  \n",
    "    print(greatest, pos)\n",
    "    output1 = [0]*36\n",
    "    output1[pos] = 1\n",
    "    print(np.unique(labels)[pos])\n",
    "    \n",
    "get_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n",
      "0.99999034 16\n",
      "ka\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('testFiles/random4.png', cv.IMREAD_GRAYSCALE )\n",
    "print(img.shape)\n",
    "img1 =img.reshape((1, 32, 32, 1))\n",
    "plt.imshow(img)\n",
    "output = new_model.predict(img1)\n",
    "\n",
    "def get_output(output1):\n",
    "    greatest = float('-inf')\n",
    "    pos = 0\n",
    "    for i in range(len(output1[0])):\n",
    "    #     print(output1[0][i], end=\", \")\n",
    "        if greatest < output1[0][i]:\n",
    "            greatest = output1[0][i]\n",
    "            pos = i  \n",
    "    print(greatest, pos)\n",
    "    output1 = [0]*36\n",
    "    output1[pos] = 1\n",
    "    print(np.unique(labels)[pos])\n",
    "    \n",
    "get_output(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2 as cv\n",
    "\n",
    "# img = cv.imread('testFiles/word1_0.png', cv.IMREAD_GRAYSCALE )\n",
    "# print(img.shape)\n",
    "# # img1 =img.reshape((1, 32, 32, 1))\n",
    "# # plt.imshow(img)\n",
    "# # output = new_model.predict(img1)\n",
    "\n",
    "# # def get_output(output1):\n",
    "# #     greatest = float('-inf')\n",
    "# #     pos = 0\n",
    "# #     for i in range(len(output1[0])):\n",
    "# #     #     print(output1[0][i], end=\", \")\n",
    "# #         if greatest < output1[0][i]:\n",
    "# #             greatest = output1[0][i]\n",
    "# #             pos = i  \n",
    "# #     print(greatest, pos)\n",
    "# #     output1 = [0]*36\n",
    "# #     output1[pos] = 1\n",
    "# #     print(np.unique(labels)[pos])\n",
    "    \n",
    "# # get_output(output)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# resizing the image of 400,400 to 32 ,32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# im = Image.open(\"testFiles/word1_0.png\")\n",
    "# orig_size = im.size\n",
    "# print(orig_size)\n",
    "# display(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im.thumbnail([32, 32])\n",
    "# display(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im.save(\"Dpi_test.png\", dpi=(32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2 as cv\n",
    "\n",
    "# img = cv.imread('Dpi_test.png', cv.IMREAD_GRAYSCALE )\n",
    "# print(img.shape)\n",
    "# # img1 =img.reshape((1, 32, 32, 1))\n",
    "# plt.imshow(img)\n",
    "# output = new_model.predict(img1)\n",
    "\n",
    "# def get_output(output1):\n",
    "#     greatest = float('-inf')\n",
    "#     pos = 0\n",
    "#     for i in range(len(output1[0])):\n",
    "#     #     print(output1[0][i], end=\", \")\n",
    "#         if greatest < output1[0][i]:\n",
    "#             greatest = output1[0][i]\n",
    "#             pos = i  \n",
    "#     print(greatest, pos)\n",
    "#     output1 = [0]*36\n",
    "#     output1[pos] = 1\n",
    "#     print(np.unique(labels)[pos])\n",
    "    \n",
    "# get_output(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n",
      "0.99156946 20\n",
      "ma\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('testFiles/check.png', cv.IMREAD_GRAYSCALE )\n",
    "print(img.shape)\n",
    "img1 =img.reshape((1, 32, 32, 1))\n",
    "plt.imshow(img)\n",
    "output = new_model.predict(img1)\n",
    "\n",
    "def get_output(output1):\n",
    "    greatest = float('-inf')\n",
    "    pos = 0\n",
    "    for i in range(len(output1[0])):\n",
    "    #     print(output1[0][i], end=\", \")\n",
    "        if greatest < output1[0][i]:\n",
    "            greatest = output1[0][i]\n",
    "            pos = i  \n",
    "    print(greatest, pos)\n",
    "    output1 = [0]*36\n",
    "    output1[pos] = 1\n",
    "    print(np.unique(labels)[pos])\n",
    "    \n",
    "get_output(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('testFiles/random5.png', cv.IMREAD_GRAYSCALE )\n",
    "print(img.shape)\n",
    "img1 =img.reshape((1, 32, 32, 1))\n",
    "plt.imshow(img)\n",
    "output = new_model.predict(img1)\n",
    "\n",
    "def get_output(output1):\n",
    "    greatest = float('-inf')\n",
    "    pos = 0\n",
    "    for i in range(len(output1[0])):\n",
    "    #     print(output1[0][i], end=\", \")\n",
    "        if greatest < output1[0][i]:\n",
    "            greatest = output1[0][i]\n",
    "            pos = i  \n",
    "    print(greatest, pos)\n",
    "    output1 = [0]*36\n",
    "    output1[pos] = 1\n",
    "    print(np.unique(labels)[pos])\n",
    "    \n",
    "get_output(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('testFiles/random6.png', cv.IMREAD_GRAYSCALE )\n",
    "print(img.shape)\n",
    "img1 =img.reshape((1, 32, 32, 1))\n",
    "plt.imshow(img)\n",
    "output = new_model.predict(img1)\n",
    "\n",
    "def get_output(output1):\n",
    "    greatest = float('-inf')\n",
    "    pos = 0\n",
    "    for i in range(len(output1[0])):\n",
    "    #     print(output1[0][i], end=\", \")\n",
    "        if greatest < output1[0][i]:\n",
    "            greatest = output1[0][i]\n",
    "            pos = i  \n",
    "    print(greatest, pos)\n",
    "    output1 = [0]*36\n",
    "    output1[pos] = 1\n",
    "    print(np.unique(labels)[pos])\n",
    "    \n",
    "get_output(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('testFiles/random1.png', cv.IMREAD_GRAYSCALE )\n",
    "print(img.shape)\n",
    "img1 =img.reshape((1, 32, 32, 1))\n",
    "plt.imshow(img)\n",
    "output = new_model.predict(img1)\n",
    "\n",
    "def get_output(output1):\n",
    "    greatest = float('-inf')\n",
    "    pos = 0\n",
    "    for i in range(len(output1[0])):\n",
    "    #     print(output1[0][i], end=\", \")\n",
    "        if greatest < output1[0][i]:\n",
    "            greatest = output1[0][i]\n",
    "            pos = i  \n",
    "    print(greatest, pos)\n",
    "    output1 = [0]*36\n",
    "    output1[pos] = 1\n",
    "    print(np.unique(labels)[pos])\n",
    "    \n",
    "get_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('testFiles/13102.png', cv.IMREAD_GRAYSCALE )\n",
    "print(img.shape)\n",
    "img1 =img.reshape((1, 32, 32, 1))\n",
    "plt.imshow(img)\n",
    "output = new_model.predict(img1)\n",
    "\n",
    "def get_output(output1):\n",
    "    greatest = float('-inf')\n",
    "    pos = 0\n",
    "    for i in range(len(output1[0])):\n",
    "    #     print(output1[0][i], end=\", \")\n",
    "        if greatest < output1[0][i]:\n",
    "            greatest = output1[0][i]\n",
    "            pos = i  \n",
    "    print(greatest, pos)\n",
    "    output1 = [0]*36\n",
    "    output1[pos] = 1\n",
    "    print(np.unique(labels)[pos])\n",
    "    \n",
    "get_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('testFiles/88606.png', cv.IMREAD_GRAYSCALE )\n",
    "print(img.shape)\n",
    "img1 =img.reshape((1, 32, 32, 1))\n",
    "plt.imshow(img)\n",
    "output = new_model.predict(img1)\n",
    "\n",
    "def get_output(output1):\n",
    "    greatest = float('-inf')\n",
    "    pos = 0\n",
    "    for i in range(len(output1[0])):\n",
    "    #     print(output1[0][i], end=\", \")\n",
    "        if greatest < output1[0][i]:\n",
    "            greatest = output1[0][i]\n",
    "            pos = i  \n",
    "    print(greatest, pos)\n",
    "    output1 = [0]*36\n",
    "    output1[pos] = 1\n",
    "    print(np.unique(labels)[pos])\n",
    "    \n",
    "get_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('testFiles/random7.png', cv.IMREAD_GRAYSCALE )\n",
    "print(img.shape)\n",
    "img1 =img.reshape((1, 32, 32, 1))\n",
    "plt.imshow(img)\n",
    "output = new_model.predict(img1)\n",
    "\n",
    "def get_output(output1):\n",
    "    greatest = float('-inf')\n",
    "    pos = 0\n",
    "    for i in range(len(output1[0])):\n",
    "    #     print(output1[0][i], end=\", \")\n",
    "        if greatest < output1[0][i]:\n",
    "            greatest = output1[0][i]\n",
    "            pos = i  \n",
    "    print(greatest, pos)\n",
    "    output1 = [0]*36\n",
    "    output1[pos] = 1\n",
    "    print(np.unique(labels)[pos])\n",
    "    \n",
    "get_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n",
      "0.99951315 12\n",
      "gya\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.2793300e-21 7.3565827e-11 1.7343479e-12 7.4253178e-15 8.5093387e-15\n",
      "  4.8419822e-04 2.7229869e-15 2.2671959e-15 5.1142386e-14 7.8771217e-22\n",
      "  2.9339133e-15 1.5902285e-12 9.9951315e-01 4.2582680e-13 1.4441562e-10\n",
      "  1.4770224e-21 4.0312922e-21 1.9059888e-13 2.9487046e-13 3.9025158e-11\n",
      "  1.5789688e-10 3.2362231e-12 3.4545322e-10 3.6162943e-14 2.6416615e-06\n",
      "  1.1615793e-17 2.1307041e-14 5.8791372e-10 4.1999384e-18 8.2730291e-14\n",
      "  3.6692024e-14 9.3640717e-27 1.8040904e-08 1.8018144e-11 3.1721747e-13\n",
      "  1.3196966e-12]]\n",
      "0.99951315 12\n",
      "gya\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('testFiles/random9.png', cv.IMREAD_GRAYSCALE )\n",
    "print(img.shape)\n",
    "img1 =img.reshape((1, 32, 32, 1))\n",
    "plt.imshow(img)\n",
    "output = new_model.predict(img1)\n",
    "\n",
    "def get_output(output1):\n",
    "    greatest = float('-inf')\n",
    "    pos = 0\n",
    "    for i in range(len(output1[0])):\n",
    "    #     print(output1[0][i], end=\", \")\n",
    "        if greatest < output1[0][i]:\n",
    "            greatest = output1[0][i]\n",
    "            pos = i  \n",
    "    print(greatest, pos)\n",
    "    output1 = [0]*36\n",
    "    output1[pos] = 1\n",
    "    print(np.unique(labels)[pos])\n",
    "    \n",
    "get_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2 as cv\n",
    "\n",
    "# img = cv.imread('testFiles/random10.png', cv.IMREAD_GRAYSCALE )\n",
    "# print(img.shape)\n",
    "# img1 =img.reshape((1, 32, 32, 1))\n",
    "# print(img1)\n",
    "# plt.imshow(img)\n",
    "# output = new_model.predict(img1)\n",
    "\n",
    "# def get_output(output1):\n",
    "#     greatest = float('-inf')\n",
    "#     pos = 0\n",
    "#     for i in range(len(output1[0])):\n",
    "#     #     print(output1[0][i], end=\", \")\n",
    "#         if greatest < output1[0][i]:\n",
    "#             greatest = output1[0][i]\n",
    "#             pos = i  \n",
    "#     print(greatest, pos)\n",
    "#     output1 = [0]*36\n",
    "#     output1[pos] = 1\n",
    "#     print(np.unique(labels)[pos])\n",
    "    \n",
    "# get_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n",
      "0.99998844 21\n",
      "motosaw\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.2427287e-13 2.3356078e-19 1.1541842e-05 3.2652236e-27 1.3305122e-23\n",
      "  3.0062186e-19 1.4659883e-31 1.2380105e-28 5.2565065e-13 2.7064345e-30\n",
      "  3.4095902e-09 1.9963690e-11 3.5668455e-17 4.6840356e-20 4.9137146e-21\n",
      "  1.3403087e-15 3.4679475e-18 6.8726451e-19 8.6456259e-10 2.1684609e-29\n",
      "  3.9850807e-21 9.9998844e-01 5.3138610e-22 5.4435898e-15 2.8066747e-13\n",
      "  2.1363387e-09 3.7341009e-18 4.4495330e-27 1.1773988e-29 1.0090512e-22\n",
      "  5.8100223e-11 1.1325266e-29 2.8912044e-09 4.6075038e-24 1.3159402e-11\n",
      "  8.0567958e-10]]\n",
      "0.99998844 21\n",
      "motosaw\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('testFiles/random10.png', cv.IMREAD_GRAYSCALE )\n",
    "print(img.shape)\n",
    "img1 =img.reshape((1, 32, 32, 1))\n",
    "plt.imshow(img)\n",
    "output = new_model.predict(img1)\n",
    "\n",
    "def get_output(output1):\n",
    "    greatest = float('-inf')\n",
    "    pos = 0\n",
    "    for i in range(len(output1[0])):\n",
    "    #     print(output1[0][i], end=\", \")\n",
    "        if greatest < output1[0][i]:\n",
    "            greatest = output1[0][i]\n",
    "            pos = i  \n",
    "    print(greatest, pos)\n",
    "    output1 = [0]*36\n",
    "    output1[pos] = 1\n",
    "    print(np.unique(labels)[pos])\n",
    "    \n",
    "get_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2 as cv\n",
    "\n",
    "# img = cv.imread('testFiles/just check.png', cv.IMREAD_GRAYSCALE )\n",
    "# print(img.shape)\n",
    "# # img1 =img.reshape((1, 32, 32, 1))\n",
    "# # img1 = img.reshape(-1, 3, 32, 32)\n",
    "# img = img.reshape(img.shape[0], 3, 32, 32)\n",
    "\n",
    "# plt.imshow(img)\n",
    "# output = new_model.predict(img1)\n",
    "\n",
    "# def get_output(output1):\n",
    "#     greatest = float('-inf')\n",
    "#     pos = 0\n",
    "#     for i in range(len(output1[0])):\n",
    "#     #     print(output1[0][i], end=\", \")\n",
    "#         if greatest < output1[0][i]:\n",
    "#             greatest = output1[0][i]\n",
    "#             pos = i  \n",
    "#     print(greatest, pos)\n",
    "#     output1 = [0]*36\n",
    "#     output1[pos] = 1\n",
    "#     print(np.unique(labels)[pos])\n",
    "    \n",
    "# get_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from PIL import Image\n",
    "# im = Image.open(\"testFiles/word1_1.png\")\n",
    "# orig_size = im.size\n",
    "# print(orig_size)\n",
    "# display(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find the shape and size of image\n",
    "# import cv2\n",
    "\n",
    "# im = cv2.imread('testFiles/word1_1.png')\n",
    "\n",
    "# print(type(im))\n",
    "# # <class 'numpy.ndarray'>\n",
    "\n",
    "# print(im.shape)\n",
    "# print(type(im.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im.thumbnail([32, 32])\n",
    "# display(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im = im.transform(orig_size, Image.EXTENT, (0,0,32,32))\n",
    "# display(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im.save(\"ma.png\", dpi=(32, 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find the shape and size of image\n",
    "# import cv2\n",
    "\n",
    "# im = cv2.imread('ma.png')\n",
    "\n",
    "# print(type(im))\n",
    "# # <class 'numpy.ndarray'>\n",
    "\n",
    "# print(im.shape)\n",
    "# print(type(im.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2 as cv\n",
    "\n",
    "# img = cv.imread('ma.png', cv.IMREAD_GRAYSCALE )\n",
    "# print(img.shape)\n",
    "# # img1 =img.reshape((1, 32, 32, 1))\n",
    "# plt.imshow(img)\n",
    "# output = new_model.predict(img1)\n",
    "\n",
    "# def get_output(output1):\n",
    "#     greatest = float('-inf')\n",
    "#     pos = 0\n",
    "#     for i in range(len(output1[0])):\n",
    "#     #     print(output1[0][i], end=\", \")\n",
    "#         if greatest < output1[0][i]:\n",
    "#             greatest = output1[0][i]\n",
    "#             pos = i  \n",
    "#     print(greatest, pos)\n",
    "#     output1 = [0]*36\n",
    "#     output1[pos] = 1\n",
    "#     print(np.unique(labels)[pos])\n",
    "    \n",
    "# get_output(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anvil.server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Connected to \"Default environment\" as SERVER\n"
     ]
    }
   ],
   "source": [
    "anvil.server.connect(\"SRO2NKWY5QYWR6OPCLQF2F5O-2LOYQ4OHB452X3G2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anvil.media \n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import PIL as image\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "@anvil.server.callable\n",
    "def classify_image(file):\n",
    "    with anvil.media.TempFile(file) as filename:\n",
    "        \n",
    "        img =load_img(filename)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    output1 = new_model.predict(img1)\n",
    "    print(output1)\n",
    "    greatest = float('-inf')\n",
    "    pos = 0\n",
    "    for i in range(len(output1[0])):\n",
    "    #     print(output1[0][i], end=\", \")\n",
    "        if greatest < output1[0][i]:\n",
    "            greatest = output1[0][i]\n",
    "            pos = i  \n",
    "    print(greatest, pos)\n",
    "    output1 = [0]*36\n",
    "    output1[pos] = 1\n",
    "    print(np.unique(labels)[pos])\n",
    "    return np.unique(labels)[pos]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
